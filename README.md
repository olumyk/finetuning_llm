# Domain Expert Model Fine-Tuning with Meta Llama 2 7B

## This project was completed to fulfill the requirements of the Nanodegree course titled "Introducing Generative AI with AWS," offered by Udacity in collaboration with AWS

## Project Overview

Welcome to the domain expert model fine-tuning project using the Meta Llama 2 7B foundation model. In this project, a specialized language model capable of generating contextually relevant text in healthcare/medical domain is created. 
This model will serve as a knowledgeable assistant, capable of enhancing user experience and streamlining information delivery.

## Project Objective

The main objective of this project is to fine-tune the Meta Llama 2 7B model on a domain-specific dataset; that is, healthcare/medical dataset. By doing so, a language model proficient in understanding and completing/generating domain-specific text is developed. This model can be utilized for applications like chatbots, internal knowledge bases, and text content generation.


## Project Tasks

### Fine-Tuning the Language Model

1. Environment Setup: Configure AWS Sagemaker resources and necessary Python libraries.
2. Model Deployment: Deploy the Meta Llama 2 7B foundation model on the AWS platform.
3. Dataset Integration: Fine-tune the model using a selected domain-specific dataset.
4. Testing and Evaluation: Evaluate the model's performance on domain-specific text generation tasks.


## Outcomes

- Gain advanced skills in machine learning and natural language processing.
- Hands-on experience with AWS Sagemaker and deploying models on cloud platforms.
- Insights into training domain-specific language models and their applications.
- Practical application of AI in solving real-world business challenges.
